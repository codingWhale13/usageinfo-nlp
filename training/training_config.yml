model: "flan-t5-base"
active_layers:
  encoder: "-5:" # use python slice syntax (e.g. ':0' for no layers and ':' for all)
  decoder: ":0"
  lm_head: True
artifact:
  name: #"scintillating-mandu-99"
  checkpoint: #9
epochs: 20
batch_size: 16
accumulate_grad_batches: 4
optimizer: #Set all parameters you do not want to null
  name: "AdamW"
  weight_decay: 0.01
  scale_parameter: True
  relative_step: True
  warmup_init: True
  lr: 0.0001
lr_scheduler_type: "OneCycleLR" #Currently supports OneCycleLR and AdaFactor. If you do not want a LR scheduler write null
dataset:
  version: "bumsebiene-69"
  validation_split: 0.10
cluster:
  devices: 1 #Number of gpus per node
  num_nodes: 1 #Number of nodes
test_run: False
multiple_usage_options_strategy: "shuffle-3"

# Options for 'multiple_usage_options_strategy':
#   - "default" -> wie gehabt kommt ein Datapoint raus, der alle usage options in gegebener Reihenfolge enthält
#   - "flat" -> ein Datapoint für jede usage option
#   - "shuffle" -> wie bei "default" ein Datapoint, aber mit zufälliger Reihenfolge
#   - "shuffle-n" -> n zufällige Datapoints mit jeweils unterschiedlichen zufälligen Permutationen
#   - "shuffle-all" -> alle Permutationen als separate Datapoints

# Further examples for 'active_layers' syntax:
#   - ':0' -> activate none
#   - ':' -> activate all ('0:') also works
#   - '-5:' -> activate last five
#   - ':3' -> activate first three
